{"instruction":"Show me all pods in the production namespace with their IP addresses and which nodes they're running on","input":{},"output":{"tool":"kubectl_get_describe_pods_status","action":"kubectl get pods -n production -o wide","result":"3 pods running: web-1 on node-1 (10.244.1.5), web-2 on node-2 (10.244.2.7), api-1 on node-1 (10.244.1.8)"}}
{"instruction":"Create a deployment called nginx-prod with the nginx:1.25 image and 5 replicas in the default namespace","input":{},"output":{"tool":"kubectl_create_deployment_with_replicas","action":"kubectl create deployment nginx-prod --image=nginx:1.25 --replicas=5 -n default","result":"Deployment created, rollout successful with 5/5 pods running"}}
{"instruction":"Apply the Kubernetes manifests from /k8s/app-stack.yaml to deploy my full application stack","input":{},"output":{"tool":"kubectl_apply_manifest_yaml_files","action":"kubectl apply -f /k8s/app-stack.yaml -n default","result":"Created: deployment.apps/web, deployment.apps/api, service/web-service, service/api-service, configmap/app-config"}}
{"instruction":"Scale up the api-server deployment to 10 replicas to handle increased traffic","input":{},"output":{"tool":"kubectl_scale_deployment_replicas","action":"kubectl scale deployment/api-server --replicas=10 -n production","result":"Scaled from 3 to 10 replicas, all pods running and ready"}}
{"instruction":"Expose my web-app deployment as a LoadBalancer service on port 8080","input":{},"output":{"tool":"kubectl_expose_service_loadbalancer","action":"kubectl expose deployment web-app --name=web-service --port=8080 --type=LoadBalancer -n default","result":"Service exposed, external IP: 34.123.45.67 on port 8080"}}
{"instruction":"Get the logs from the api-backend-7d5f6b8c9-k3m4n pod to debug the 500 errors","input":{},"output":{"tool":"kubectl_logs_exec_pod_diagnostics","action":"kubectl logs api-backend-7d5f6b8c9-k3m4n -n production --tail=50 --timestamps","result":"Error found: Database connection timeout at 2025-11-18T14:45:23Z"}}
{"instruction":"Delete the old-deployment in the staging namespace as it's no longer needed","input":{},"output":{"tool":"kubectl_delete_resources_cleanup","action":"kubectl delete deployment old-deployment -n staging","result":"deployment.apps 'old-deployment' deleted, 3 pods terminated"}}
{"instruction":"Describe the web-frontend-6f8g9h0-p2q3r pod to see why it's in CrashLoopBackOff","input":{},"output":{"tool":"kubectl_get_describe_pods_status","action":"kubectl describe pod web-frontend-6f8g9h0-p2q3r -n default","result":"Events show: Back-off restarting failed container, Exit Code 1, OOMKilled"}}
{"instruction":"Create a Redis deployment with 1 replica using the redis:7-alpine image in the cache namespace","input":{},"output":{"tool":"kubectl_create_deployment_with_replicas","action":"kubectl create deployment redis-cache --image=redis:7-alpine --replicas=1 -n cache","result":"Redis deployment created, pod running on worker-2"}}
{"instruction":"Apply updated configuration from /k8s/backend-v2.yaml to perform rolling update","input":{},"output":{"tool":"kubectl_apply_manifest_yaml_files","action":"kubectl apply -f /k8s/backend-v2.yaml -n production","result":"deployment.apps/backend configured, rolling update initiated"}}
{"instruction":"Check the current number of replicas for the worker-queue deployment","input":{},"output":{"tool":"kubectl_scale_deployment_replicas","action":"kubectl get deployment worker-queue -n default -o jsonpath='{.spec.replicas}'","result":"Current replicas: 4"}}
{"instruction":"Expose the postgres-db deployment as a ClusterIP service on port 5432","input":{},"output":{"tool":"kubectl_expose_service_loadbalancer","action":"kubectl expose deployment postgres-db --name=postgres-service --port=5432 --type=ClusterIP -n database","result":"Internal service created with ClusterIP 10.96.145.78"}}
{"instruction":"Execute a health check command inside the app-server-8c9d0e1-r5s6t pod","input":{},"output":{"tool":"kubectl_logs_exec_pod_diagnostics","action":"kubectl exec app-server-8c9d0e1-r5s6t -n production -- curl -f http://localhost:8080/health","result":"HTTP 200 OK - application healthy"}}
{"instruction":"Delete the test-service in the dev namespace","input":{},"output":{"tool":"kubectl_delete_resources_cleanup","action":"kubectl delete service test-service -n dev","result":"service 'test-service' deleted"}}
{"instruction":"Get detailed information about all pods in the monitoring namespace","input":{},"output":{"tool":"kubectl_get_describe_pods_status","action":"kubectl get pods -n monitoring -o wide","result":"prometheus-1 (Running), grafana-1 (Running), alertmanager-1 (Running)"}}
{"instruction":"Deploy the payment microservice with 3 replicas using payment-api:v2.1 image","input":{},"output":{"tool":"kubectl_create_deployment_with_replicas","action":"kubectl create deployment payment-service --image=payment-api:v2.1 --replicas=3 -n production","result":"Payment service deployed with 3 pods across 2 nodes"}}
{"instruction":"Apply Kubernetes resources from the entire /k8s/infrastructure directory","input":{},"output":{"tool":"kubectl_apply_manifest_yaml_files","action":"kubectl apply -f /k8s/infrastructure/ -n default","result":"Applied 12 resources: 4 deployments, 4 services, 2 configmaps, 2 secrets"}}
{"instruction":"Scale down the batch-processor deployment to 2 replicas during off-peak hours","input":{},"output":{"tool":"kubectl_scale_deployment_replicas","action":"kubectl scale deployment/batch-processor --replicas=2 -n jobs","result":"Scaled down from 8 to 2 replicas, 6 pods terminated gracefully"}}
{"instruction":"Expose frontend deployment as NodePort service on port 3000","input":{},"output":{"tool":"kubectl_expose_service_loadbalancer","action":"kubectl expose deployment frontend --name=frontend-service --port=3000 --type=NodePort -n default","result":"Service exposed on NodePort 31245, accessible on all nodes"}}
{"instruction":"View the last 100 log lines from the worker-1-7f8g9h0-t6u7v pod's worker container","input":{},"output":{"tool":"kubectl_logs_exec_pod_diagnostics","action":"kubectl logs worker-1-7f8g9h0-t6u7v -n jobs -c worker --tail=100","result":"Processed 1,247 jobs, queue empty, worker idle"}}
{"instruction":"Remove the old-api-v1 deployment from production namespace","input":{},"output":{"tool":"kubectl_delete_resources_cleanup","action":"kubectl delete deployment old-api-v1 -n production","result":"Deployment deleted, 5 pods terminated"}}
{"instruction":"Check the status and events of pod database-primary-0 in the database namespace","input":{},"output":{"tool":"kubectl_get_describe_pods_status","action":"kubectl describe pod database-primary-0 -n database","result":"Pod healthy, 1/1 containers ready, no recent events or errors"}}
{"instruction":"Create an Elasticsearch deployment with 3 replicas using elasticsearch:8.11 image","input":{},"output":{"tool":"kubectl_create_deployment_with_replicas","action":"kubectl create deployment elasticsearch --image=elasticsearch:8.11 --replicas=3 -n logging","result":"Elasticsearch cluster deployed with 3 pods"}}
{"instruction":"Deploy the complete monitoring stack from /k8s/monitoring-stack.yaml","input":{},"output":{"tool":"kubectl_apply_manifest_yaml_files","action":"kubectl apply -f /k8s/monitoring-stack.yaml -n monitoring","result":"Deployed prometheus, grafana, alertmanager, node-exporter"}}
{"instruction":"Increase replicas for the web-frontend deployment from 5 to 15 for Black Friday traffic","input":{},"output":{"tool":"kubectl_scale_deployment_replicas","action":"kubectl scale deployment/web-frontend --replicas=15 -n production","result":"Scaled to 15/15 replicas, new pods distributed across 5 nodes"}}
{"instruction":"Create a service to expose the rabbitmq deployment on port 5672 as ClusterIP","input":{},"output":{"tool":"kubectl_expose_service_loadbalancer","action":"kubectl expose deployment rabbitmq --name=rabbitmq-service --port=5672 --type=ClusterIP -n messaging","result":"RabbitMQ service created with ClusterIP 10.96.87.123"}}
{"instruction":"Get environment variables from the config-server-9e0f1a2-w8x9y pod","input":{},"output":{"tool":"kubectl_logs_exec_pod_diagnostics","action":"kubectl exec config-server-9e0f1a2-w8x9y -n default -- env","result":"APP_ENV=production, DB_HOST=postgres-service, REDIS_HOST=redis-service"}}
{"instruction":"Delete all resources with label app=old-version in the staging namespace","input":{},"output":{"tool":"kubectl_delete_resources_cleanup","action":"kubectl delete all -l app=old-version -n staging","result":"Deleted 2 deployments, 2 services, 8 pods"}}
{"instruction":"Show me the current state of the cache-redis-5g6h7i8-z0a1b pod","input":{},"output":{"tool":"kubectl_get_describe_pods_status","action":"kubectl get pod cache-redis-5g6h7i8-z0a1b -n cache -o jsonpath='{.status.phase}'","result":"Running"}}
{"instruction":"Deploy machine learning model serving with 2 replicas using ml-serve:v3.2","input":{},"output":{"tool":"kubectl_create_deployment_with_replicas","action":"kubectl create deployment ml-model --image=ml-serve:v3.2 --replicas=2 -n ml","result":"ML model deployment created with GPU-enabled pods"}}
{"instruction":"Apply the ingress configuration from /k8s/ingress.yaml to route external traffic","input":{},"output":{"tool":"kubectl_apply_manifest_yaml_files","action":"kubectl apply -f /k8s/ingress.yaml -n default","result":"ingress.networking.k8s.io/main-ingress configured"}}
{"instruction":"Set the auth-service deployment to 6 replicas for high availability","input":{},"output":{"tool":"kubectl_scale_deployment_replicas","action":"kubectl scale deployment/auth-service --replicas=6 -n production","result":"Deployment scaled to 6/6 replicas"}}
{"instruction":"Expose the grafana deployment on port 3000 as LoadBalancer for external access","input":{},"output":{"tool":"kubectl_expose_service_loadbalancer","action":"kubectl expose deployment grafana --name=grafana-external --port=3000 --type=LoadBalancer -n monitoring","result":"External service created, LoadBalancer IP pending"}}
{"instruction":"Check application logs from the api-v2-1b2c3d4-e5f6g pod's api container","input":{},"output":{"tool":"kubectl_logs_exec_pod_diagnostics","action":"kubectl logs api-v2-1b2c3d4-e5f6g -n production -c api --tail=75","result":"Serving 234 req/sec, avg latency 45ms, 0 errors"}}
{"instruction":"Clean up the test-deployment and its associated resources in dev namespace","input":{},"output":{"tool":"kubectl_delete_resources_cleanup","action":"kubectl delete deployment test-deployment -n dev","result":"Deployment and 4 pods deleted successfully"}}
