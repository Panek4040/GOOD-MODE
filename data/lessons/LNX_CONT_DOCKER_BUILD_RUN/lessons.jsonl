{"instruction":"Build a Docker image for my Node.js API from the Dockerfile in /app/api directory and tag it as node-api:latest","input":{},"output":{"tool":"docker_build_image_from_dockerfile","action":"docker build -t node-api:latest -f /app/api/Dockerfile /app/api","result":"Image built successfully, size 245MB, ID sha256:abc123def456"}}
{"instruction":"Run an Nginx container named web-server mapping port 8080 on host to port 80 in container with /data/www mounted to /usr/share/nginx/html","input":{},"output":{"tool":"docker_run_container_with_ports_volumes","action":"docker run -d --name web-server -p 8080:80 -v /data/www:/usr/share/nginx/html nginx:alpine","result":"Container web-server started, accessible on localhost:8080"}}
{"instruction":"Start my microservices stack using the docker-compose.yml in /opt/myapp directory with project name production","input":{},"output":{"tool":"docker_compose_multi_container_orchestration","action":"docker-compose -f /opt/myapp/docker-compose.yml -p production up -d","result":"Started 5 services: production-web-1, production-api-1, production-db-1, production-redis-1, production-worker-1"}}
{"instruction":"Check the last 100 log lines from the container named api-server to debug the 500 error","input":{},"output":{"tool":"docker_inspect_logs_container_diagnostics","action":"docker logs --tail 100 --timestamps api-server","result":"Found error: [ERROR] Database connection timeout at 2025-11-18T14:23:45.678Z"}}
{"instruction":"Execute database migration script inside the web-app container","input":{},"output":{"tool":"docker_exec_interactive_shell_commands","action":"docker exec web-app bash -c 'python manage.py migrate'","result":"Applied 12 migrations successfully"}}
{"instruction":"Stop and remove the old-api container to free up resources","input":{},"output":{"tool":"docker_container_lifecycle_stop_remove","action":"docker stop old-api && docker rm old-api","result":"Container old-api stopped and removed"}}
{"instruction":"Create a Docker image from /home/dev/python-worker/Dockerfile and tag it as worker:v2.1","input":{},"output":{"tool":"docker_build_image_from_dockerfile","action":"docker build -t worker:v2.1 -f /home/dev/python-worker/Dockerfile /home/dev/python-worker","result":"Build completed in 87.3s, image size 412MB"}}
{"instruction":"Launch a PostgreSQL container with custom network called db-net, 1GB memory limit, and environment variables for production","input":{},"output":{"tool":"docker_run_with_env_network_limits","action":"docker network create db-net && docker run -d --network db-net --memory 1g -e POSTGRES_PASSWORD=secret -e POSTGRES_DB=prod postgres:15","result":"Container running on db-net with 1GB memory limit"}}
{"instruction":"Check if my backend-api container is running and show its resource usage","input":{},"output":{"tool":"docker_inspect_logs_container_diagnostics","action":"docker stats backend-api --no-stream","result":"backend-api using 3.2% CPU, 156MB/512MB memory, network I/O: 2.3MB/1.8MB"}}
{"instruction":"Run a health check command inside the nginx-proxy container to verify it's responding","input":{},"output":{"tool":"docker_exec_interactive_shell_commands","action":"docker exec nginx-proxy curl -f http://localhost/health","result":"HTTP 200 OK - Nginx healthy"}}
{"instruction":"Build Docker image with build arguments for my React app and tag as frontend:prod","input":{},"output":{"tool":"docker_build_image_from_dockerfile","action":"docker build --build-arg NODE_ENV=production --build-arg API_URL=https://api.prod.com -t frontend:prod /var/www/react-app","result":"Image frontend:prod built with production config, size 89MB"}}
{"instruction":"Deploy my full stack application using docker-compose in /srv/fullstack with all services","input":{},"output":{"tool":"docker_compose_multi_container_orchestration","action":"docker-compose -f /srv/fullstack/docker-compose.yml -p fullstack up -d","result":"Network fullstack_default created, 7 containers started successfully"}}
{"instruction":"Investigate why the worker-queue container keeps restarting by checking its logs","input":{},"output":{"tool":"docker_inspect_logs_container_diagnostics","action":"docker logs worker-queue --tail 50","result":"OOMKilled - container exceeded 512MB memory limit, killed by kernel"}}
{"instruction":"Run Redis container with 2GB memory limit and 2 CPU cores on isolated network","input":{},"output":{"tool":"docker_run_with_env_network_limits","action":"docker network create cache-net && docker run -d --name redis-cache --network cache-net --memory 2g --cpus 2 redis:7-alpine","result":"Redis running on cache-net with resource limits applied"}}
{"instruction":"Get detailed inspection of the db-primary container's state and configuration","input":{},"output":{"tool":"docker_inspect_logs_container_diagnostics","action":"docker inspect db-primary --format '{{json .State}}'","result":"Status: running, PID: 45678, Started: 2025-11-18T10:15:32Z, Health: healthy"}}
{"instruction":"Execute npm install inside the node-app container to update dependencies","input":{},"output":{"tool":"docker_exec_interactive_shell_commands","action":"docker exec node-app bash -c 'cd /app && npm install'","result":"Added 47 packages, updated 12 packages in 23.4s"}}
{"instruction":"Stop the test-runner container and remove it after tests complete","input":{},"output":{"tool":"docker_container_lifecycle_stop_remove","action":"docker stop test-runner && docker rm test-runner","result":"test-runner stopped and cleaned up"}}
{"instruction":"Build optimized production image for Java Spring Boot app with multi-stage Dockerfile","input":{},"output":{"tool":"docker_build_image_from_dockerfile","action":"docker build -t spring-api:prod-v3 -f /opt/java/Dockerfile.prod /opt/java","result":"Multi-stage build completed, final image 178MB (reduced from 650MB)"}}
{"instruction":"Run Elasticsearch container with custom JVM heap settings via environment variables","input":{},"output":{"tool":"docker_run_with_env_network_limits","action":"docker run -d --name elasticsearch --memory 4g -e ES_JAVA_OPTS='-Xms2g -Xmx2g' -e discovery.type=single-node elasticsearch:8.11","result":"Elasticsearch started with 2GB heap on single-node mode"}}
{"instruction":"Check real-time logs from the api-gateway container to monitor incoming requests","input":{},"output":{"tool":"docker_inspect_logs_container_diagnostics","action":"docker logs -f api-gateway","result":"[2025-11-18 14:45:12] GET /api/users 200 45ms\n[2025-11-18 14:45:13] POST /api/auth 201 123ms"}}
{"instruction":"Run database backup script inside postgres-prod container","input":{},"output":{"tool":"docker_exec_interactive_shell_commands","action":"docker exec postgres-prod bash -c 'pg_dump -U postgres proddb > /backups/dump_$(date +%Y%m%d).sql'","result":"Database backup saved to /backups/dump_20251118.sql (2.3GB)"}}
{"instruction":"Launch MongoDB container with authentication on custom network with 512MB RAM limit","input":{},"output":{"tool":"docker_run_with_env_network_limits","action":"docker network create mongo-net && docker run -d --name mongodb --network mongo-net --memory 512m -e MONGO_INITDB_ROOT_USERNAME=admin -e MONGO_INITDB_ROOT_PASSWORD=pass123 mongo:7","result":"MongoDB running on mongo-net with authentication enabled"}}
{"instruction":"Build Docker image for my machine learning model API and tag it as ml-api:v1.5","input":{},"output":{"tool":"docker_build_image_from_dockerfile","action":"docker build -t ml-api:v1.5 /ml/model-api","result":"Image built with TensorFlow 2.14, size 1.8GB"}}
{"instruction":"Start all services defined in docker-compose.yml for the dev environment","input":{},"output":{"tool":"docker_compose_multi_container_orchestration","action":"docker-compose -f docker-compose.yml -p dev-env up -d","result":"Started dev-env-frontend-1, dev-env-backend-1, dev-env-postgres-1"}}
{"instruction":"Get container stats for all running containers to check resource usage","input":{},"output":{"tool":"docker_inspect_logs_container_diagnostics","action":"docker stats --no-stream --format 'table {{.Name}}\\t{{.CPUPerc}}\\t{{.MemUsage}}'","result":"web-1: 1.2% CPU, 142MB/512MB\ndb-1: 8.7% CPU, 456MB/1GB\nworker-1: 23.4% CPU, 287MB/512MB"}}
{"instruction":"Run Python script inside data-processor container to process CSV files","input":{},"output":{"tool":"docker_exec_interactive_shell_commands","action":"docker exec data-processor python /scripts/process_data.py --input /data/raw --output /data/processed","result":"Processed 15,234 records in 12.3 seconds"}}
{"instruction":"Stop all containers in the old-stack project and remove them","input":{},"output":{"tool":"docker_container_lifecycle_stop_remove","action":"docker stop $(docker ps -q --filter 'name=old-stack') && docker rm $(docker ps -aq --filter 'name=old-stack')","result":"Stopped and removed 6 containers from old-stack"}}
{"instruction":"Build custom Nginx image with my configuration and tag as nginx-custom:latest","input":{},"output":{"tool":"docker_build_image_from_dockerfile","action":"docker build -t nginx-custom:latest -f /etc/nginx/Dockerfile /etc/nginx","result":"Custom Nginx image built with SSL configs, size 45MB"}}
{"instruction":"Deploy RabbitMQ with management plugin on custom network with resource limits","input":{},"output":{"tool":"docker_run_with_env_network_limits","action":"docker network create messaging && docker run -d --name rabbitmq --network messaging --memory 1g --cpus 1.5 -e RABBITMQ_DEFAULT_USER=admin rabbitmq:3-management","result":"RabbitMQ running with management UI on port 15672"}}
{"instruction":"View the last 200 lines of logs from the crashed-app container to debug the crash","input":{},"output":{"tool":"docker_inspect_logs_container_diagnostics","action":"docker logs --tail 200 crashed-app","result":"Segmentation fault at line 457 in process.c, core dumped"}}
{"instruction":"Execute database index rebuild inside mysql-primary container","input":{},"output":{"tool":"docker_exec_interactive_shell_commands","action":"docker exec mysql-primary bash -c 'mysql -u root -p$MYSQL_ROOT_PASSWORD -e \"OPTIMIZE TABLE users, orders, products\"'","result":"3 tables optimized, reclaimed 2.1GB space"}}
{"instruction":"Run Grafana container with persistent volume and custom admin password","input":{},"output":{"tool":"docker_run_container_with_ports_volumes","action":"docker run -d --name grafana -p 3000:3000 -v /opt/grafana:/var/lib/grafana -e GF_SECURITY_ADMIN_PASSWORD=mypass grafana/grafana","result":"Grafana accessible on localhost:3000 with data persisted to /opt/grafana"}}
{"instruction":"Deploy complete monitoring stack with Prometheus, Grafana, and AlertManager using compose","input":{},"output":{"tool":"docker_compose_multi_container_orchestration","action":"docker-compose -f /opt/monitoring/docker-compose.yml -p monitoring up -d","result":"Monitoring stack deployed: prometheus-1, grafana-1, alertmanager-1, node-exporter-1"}}
{"instruction":"Check if the cache-warmer container completed its job successfully","input":{},"output":{"tool":"docker_inspect_logs_container_diagnostics","action":"docker inspect cache-warmer --format '{{.State.ExitCode}} - {{.State.Status}}'","result":"0 - exited (container completed successfully)"}}
{"instruction":"Run cleanup script inside app-server to free disk space","input":{},"output":{"tool":"docker_exec_interactive_shell_commands","action":"docker exec app-server bash -c 'find /tmp -type f -mtime +7 -delete && df -h'","result":"Deleted 847 old files, freed 3.2GB, /tmp now 12GB available"}}
