{
  "name": "beautiful_soup_html_parsing",
  "description": "Parse and extract data from HTML with BeautifulSoup",
  "pattern": "beautifulsoup|bs4|html.*parse|soup.*find",
  "parameters": ["url", "selector"],
  "sequence": [
    {
      "action": {"type": "system_command", "tool": "shell", "operation": "run", "command": "python3", "args": ["-c", "from bs4 import BeautifulSoup; import requests; html = requests.get('https://example.com').text; soup = BeautifulSoup(html, 'html.parser'); print('Title:', soup.title.string); print('First paragraph:', soup.find('p').get_text())"]},
      "expected_output": {"type": "string", "example": "Title: Example Domain\nFirst paragraph: This domain is for use in illustrative examples...\n\nHTML parsed and data extracted"}
    },
    {
      "action": {"type": "system_command", "tool": "shell", "operation": "run", "command": "python3", "args": ["-c", "from bs4 import BeautifulSoup; import requests; html = requests.get('https://example.com').text; soup = BeautifulSoup(html, 'html.parser'); links = soup.find_all('a'); print(f'Found {len(links)} links:'); [print(f'  {link.get(\"href\")}') for link in links]"]},
      "expected_output": {"type": "string", "example": "Found 1 links:\n  https://www.iana.org/domains/example\n\nAll links extracted"}
    },
    {
      "action": {"type": "system_command", "tool": "shell", "operation": "run", "command": "python3", "args": ["-c", "from bs4 import BeautifulSoup; import requests; html = requests.get('https://example.com').text; soup = BeautifulSoup(html, 'html.parser'); heading = soup.select_one('h1').text; paragraphs = [p.text for p in soup.select('p')]; print('Heading:', heading); print('Paragraphs:', len(paragraphs))"]},
      "expected_output": {"type": "string", "example": "Heading: Example Domain\nParagraphs: 2\n\nCSS selectors used for extraction"}
    }
  ],
  "stats": {"uses": 0, "successes": 0, "failures": 0, "success_rate": 0.0},
  "created_by": "neural_mesh_v5.2_generator"
}
